
# streamlit_sections_preview.py
# ëª©ì : PDF ì „ì²´ í…ìŠ¤íŠ¸ â†’ ì„¹ì…˜(1~16) ë¼ì¸ì•µì»¤ ê¸°ë°˜ ìŠ¬ë¼ì´ì‹± â†’ ì„¹ì…˜ë³„ ë¯¸ë¦¬ë³´ê¸°/ë‹¤ìš´ë¡œë“œ/ë””ë²„ê¹…
# ì˜ì¡´: streamlit, PyMuPDF (fitz)

import os
import re
import io
import fitz  # PyMuPDF
import streamlit as st
import pandas as pd

st.set_page_config(page_title="MSDS Section Slicing Preview", layout="wide")
st.title("MSDS Section Slicing Preview (1~16ë²ˆ ì„¹ì…˜ ìë¥´ê¸°)")

# ---------- ìœ í‹¸ ----------
def read_pdf_text(pdf_path: str) -> str:
    buf = []
    try:
        with fitz.open(pdf_path) as doc:
            for i in range(len(doc)):
                try:
                    t = doc.load_page(i).get_text("text") or ""
                except Exception:
                    t = ""
                # í˜ì´ì§€ êµ¬ë¶„ìê°€ ìˆì–´ì•¼ í—¤ë” ì •ê·œì‹ì´ ë” ì˜ ë§ëŠ”ë‹¤
                buf.append(f"\n\n---- PAGE {i+1} ----\n{t}")
    except Exception as e:
        st.error(f"PDF ì—´ê¸° ì‹¤íŒ¨: {e}")
        return ""
    return "\n".join(buf)

def to_txt_bytes(s: str) -> bytes:
    return (s or "").encode("utf-8-sig")

# ---------- ì„¹ì…˜ ì•µì»¤(1~16) ----------
# ê° í•­ëª©ì— ë²ˆí˜¸í˜•, êµ­ë¬¸, ì˜ë¬¸(ëŒ€í‘œ) íŒ¨í„´ì„ í¬í•¨
SECTION_PATTERNS = {
    "1_identification": [
        r"(?m)^\s*1\s*[\).\s]?\s*(í™”í•™ì œí’ˆê³¼\s*íšŒì‚¬ì—\s*ê´€í•œ\s*ì •ë³´|ì œí’ˆ\s*ë°\s*íšŒì‚¬\s*ì‹ë³„)\b",
        r"(?im)^\s*section\s*1\s*[:\.\-]?\s*(identification)\b",
    ],
    "2_hazards": [
        r"(?m)^\s*2\s*[\).\s]?\s*(ìœ í•´\s*ìœ„í—˜ì„±|ìœ í•´[Â·\.\s]*ìœ„í—˜ì„±)\b",
        r"(?im)^\s*section\s*2\s*[:\.\-]?\s*(hazards)\b",
    ],
    "3_composition": [
        r"(?m)^\s*3\s*[\).\s]?\s*(êµ¬ì„±ì„±ë¶„ì˜\s*ëª…ì¹­\s*ë°\s*í•¨ìœ ëŸ‰|ëª…ì¹­\s*ë°\s*í•¨ìœ ëŸ‰|êµ¬ì„±\s*ì„±ë¶„)\b",
        r"(?im)^\s*section\s*3\s*[:\.\-]?\s*(composition|information\s+on\s+ingredients|ingredients?)\b",
    ],
    "4_first_aid": [
        r"(?m)^\s*4\s*[\).\s]?\s*(ì‘ê¸‰ì¡°ì¹˜)\b",
        r"(?im)^\s*section\s*4\s*[:\.\-]?\s*(first\s*-?\s*aid)\b",
    ],
    "5_firefighting": [
        r"(?m)^\s*5\s*[\).\s]?\s*(í™”ì¬\s*ì§„ì••\s*ìš”ë ¹|í™”ì¬ì§„ì••|í™”ì¬ì‹œ\s*ì¡°ì¹˜)\b",
        r"(?im)^\s*section\s*5\s*[:\.\-]?\s*(fire[-\s]*fighting\s*measures)\b",
    ],
    "6_accidental_release": [
        r"(?m)^\s*6\s*[\).\s]?\s*(ëˆ„ì¶œ\s*ì‚¬ê³ \s*ëŒ€ì‘|ëˆ„ì¶œ\s*ëŒ€ì‘)\b",
        r"(?im)^\s*section\s*6\s*[:\.\-]?\s*(accidental\s*release\s*measures)\b",
    ],
    "7_handling_storage": [
        r"(?m)^\s*7\s*[\).\s]?\s*(ì·¨ê¸‰\s*ë°\s*ì €ì¥|ì·¨ê¸‰/ì €ì¥)\b",
        r"(?im)^\s*section\s*7\s*[:\.\-]?\s*(handling\s*and\s*storage)\b",
    ],
    "8_exposure_controls": [
        r"(?m)^\s*8\s*[\).\s]?\s*(ë…¸ì¶œ\s*ë°©ì§€\s*ë°\s*ê°œì¸ë³´í˜¸êµ¬|ë…¸ì¶œë°©ì§€\s*ë°\s*ê°œì¸ë³´í˜¸êµ¬)\b",
        r"(?im)^\s*section\s*8\s*[:\.\-]?\s*(exposure\s*controls?|personal\s*protection)\b",
    ],
    "9_physical_chemical": [
        r"(?m)^\s*9\s*[\).\s]?\s*(ë¬¼ë¦¬\s*í™”í•™ì \s*íŠ¹ì„±|ë¬¼ë¦¬Â·í™”í•™ì \s*íŠ¹ì„±)\b",
        r"(?im)^\s*section\s*9\s*[:\.\-]?\s*(physical\s*and\s*chemical\s*properties)\b",
    ],
    "10_stability_reactivity": [
        r"(?m)^\s*10\s*[\).\s]?\s*(ì•ˆì •ì„±\s*ë°\s*ë°˜ì‘ì„±|ì•ˆì •ì„±/ë°˜ì‘ì„±)\b",
        r"(?im)^\s*section\s*10\s*[:\.\-]?\s*(stability\s*and\s*reactivity)\b",
    ],
    "11_toxicological": [
        r"(?m)^\s*11\s*[\).\s]?\s*(ë…ì„±\s*ì—\s*ê´€í•œ\s*ì •ë³´|ë…ì„±)\b",
        r"(?im)^\s*section\s*11\s*[:\.\-]?\s*(toxicological\s*information)\b",
    ],
    "12_ecological": [
        r"(?m)^\s*12\s*[\).\s]?\s*(ìƒíƒœ\s*ì—\s*ê´€í•œ\s*ì •ë³´|í™˜ê²½\s*ì—\s*ë¯¸ì¹˜ëŠ”\s*ì˜í–¥)\b",
        r"(?im)^\s*section\s*12\s*[:\.\-]?\s*(ecological\s*information)\b",
    ],
    "13_disposal": [
        r"(?m)^\s*13\s*[\).\s]?\s*(íê¸°\s*ì‹œ\s*ì£¼ì˜ì‚¬í•­|íê¸°)\b",
        r"(?im)^\s*section\s*13\s*[:\.\-]?\s*(disposal\s*considerations)\b",
    ],
    "14_transport": [
        r"(?m)^\s*14\s*[\).\s]?\s*(ìš´ì†¡ì—\s*í•„ìš”í•œ\s*ì •ë³´|ìš´ì†¡)\b",
        r"(?im)^\s*section\s*14\s*[:\.\-]?\s*(transport\s*information)\b",
    ],
    "15_regulatory": [
        r"(?m)^\s*15\s*[\).\s]?\s*(ë²•ì \s*ê·œì œ\s*ì—\s*ê´€í•œ\s*ì •ë³´|ë²•ì \s*ê·œì œí˜„í™©|ê·œì œ\s*ì •ë³´)\b",
        r"(?im)^\s*section\s*15\s*[:\.\-]?\s*(regulatory\s*information)\b",
    ],
    "16_other_information": [
        r"(?m)^\s*16\s*[\).\s]?\s*(ê·¸\s*ë°–ì˜\s*ì°¸ê³ ì‚¬í•­|ê¸°íƒ€\s*ì°¸ê³ ì‚¬í•­|ê¸°íƒ€)\b",
        r"(?im)^\s*section\s*16\s*[:\.\-]?\s*(other\s*information)\b",
    ],
}

def split_sections(text: str):
    """
    ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ ì„¹ì…˜ í—¤ë”ë¥¼ íƒì§€í•´ {key: {"title":..., "start":idx, "end":idx, "text":...}} ë°˜í™˜
    - í—¤ë”ëŠ” ë©€í‹°ë¼ì¸ ì•µì»¤ë¡œ ë§¤ì¹˜
    - ë‹¤ìŒ í—¤ë” ì‹œì‘ ì§ì „ê¹Œì§€ë¥¼ í•´ë‹¹ ì„¹ì…˜ ë³¸ë¬¸ìœ¼ë¡œ ê°„ì£¼
    """
    if not text:
        return {}, [], []

    # 1) í—¤ë” ìœ„ì¹˜ ì°¾ê¸°
    hits = []
    for key, pats in SECTION_PATTERNS.items():
        for pat in pats:
            try:
                m = re.search(pat, text, re.I | re.M)
            except re.error:
                continue
            if m:
                hits.append((m.start(), m.end(), key, m.group(0)))
                break  # ê°™ì€ keyì— ëŒ€í•´ ì²« ë§¤ì¹˜ë§Œ ì‚¬ìš©

    logs = []
    if not hits:
        logs.append("[split] í—¤ë”ë¥¼ ì°¾ì§€ ëª»í•¨")
        return {}, logs, []

    # 2) ìœ„ì¹˜ ì •ë ¬
    hits.sort(key=lambda x: x[0])  # start ê¸°ì¤€
    # 3) êµ¬ê°„í™”
    sections = {}
    for i, (s, e, key, head) in enumerate(hits):
        nxt = hits[i+1][0] if i+1 < len(hits) else len(text)
        body = text[e:nxt]
        sections[key] = {
            "title": head.strip(),
            "start": s,
            "end": nxt,
            "text": body.strip(),
            "header_span": (s, e),
        }
    logs.append(f"[split] ê°ì§€ëœ ì„¹ì…˜ ìˆ˜: {len(sections)}")
    # 4) ìˆœì„œ
    order = [k for _,_,k,_ in hits]
    return sections, logs, order

# ---------- UI ----------
st.write("PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì™€ 1~16 ì„¹ì…˜ ìŠ¬ë¼ì´ì‹± ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
files = st.file_uploader("MSDS PDF ì—…ë¡œë“œ(ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["pdf"], accept_multiple_files=True)
if not files:
    st.stop()

summary_rows = []

for idx, up in enumerate(files, start=1):
    st.markdown("---")
    st.subheader(f"ğŸ“„ {up.name}")

    # ì„ì‹œ ì €ì¥
    tmpdir = st.session_state.get("tmpdir") or os.getcwd()
    path = os.path.join(tmpdir, f"__tmp_{idx}_{up.name}")
    with open(path, "wb") as f:
        f.write(up.getbuffer())

    # ì „ì²´ í…ìŠ¤íŠ¸
    full_text = read_pdf_text(path)
    st.caption(f"ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text):,} chars")
    c1, c2 = st.columns([3,1])
    with c1:
        st.text_area("ì „ì²´ í…ìŠ¤íŠ¸(ì•ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸°)", value=full_text[:3000] + ("â€¦" if len(full_text) > 3000 else ""), height=260)
    with c2:
        st.download_button("TXT ë‹¤ìš´ë¡œë“œ(ì „ì²´)", data=to_txt_bytes(full_text), file_name=f"{os.path.splitext(up.name)[0]}__full.txt", use_container_width=True)

    # ìŠ¬ë¼ì´ì‹±
    sections, split_logs, order = split_sections(full_text)
    if split_logs:
        st.code("\n".join(split_logs), language="text")

    if not sections:
        st.warning("ì„¹ì…˜ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í—¤ë” ë¬¸êµ¬ê°€ ë‹¤ë¥´ë‹¤ë©´ ì •ê·œì‹ì„ ë³´ê°•í•´ì•¼ í•©ë‹ˆë‹¤)")
        continue

    # í‘œ í˜•ì‹ ìš”ì•½
    rows = []
    for k in order:
        s = sections[k]
        rows.append({
            "key": k,
            "title": re.sub(r"\s+", " ", s["title"])[:80],
            "start": s["start"],
            "end": s["end"],
            "length": len(s["text"]),
        })
    df = pd.DataFrame(rows)
    st.dataframe(df, use_container_width=True, hide_index=True)

    # ì„¹ì…˜ë³„ ë¯¸ë¦¬ë³´ê¸°/ë‹¤ìš´ë¡œë“œ
    st.markdown("#### ì„¹ì…˜ë³„ ë¯¸ë¦¬ë³´ê¸°")
    prev_len = st.slider("ë¯¸ë¦¬ë³´ê¸° ê¸€ì ìˆ˜", 300, 4000, 1200, 100, key=f"prev_{idx}")
    grid = st.columns(4)
    for i, k in enumerate(order):
        col = grid[i % 4]
        with col:
            s = sections[k]
            title = s["title"]
            body = s["text"]
            st.caption(f"{k} â€” {title[:60]}")
            st.text_area(f"{k}_{idx}", value=body[:prev_len] + ("â€¦" if len(body) > prev_len else ""), height=220, key=f"ta_{k}_{idx}")
            st.download_button("TXT ë‹¤ìš´ë¡œë“œ", data=to_txt_bytes(body), file_name=f"{os.path.splitext(up.name)[0]}__{k}.txt", use_container_width=True)

    # ì„¹ì…˜3 ì›ë¬¸ ê°•ì¡°
    st.markdown("#### ì„¹ì…˜3(êµ¬ì„±ì„±ë¶„) ì›ë¬¸ ì „ë¬¸")
    sec3 = sections.get("3_composition", {}).get("text", "")
    c3a, c3b = st.columns([3,1])
    with c3a:
        st.text_area("ì„¹ì…˜3 ì „ì²´ í…ìŠ¤íŠ¸", value=sec3 or "(ì„¹ì…˜3ì„ ì°¾ì§€ ëª»í•¨)", height=260, key=f"sec3_{idx}")
    with c3b:
        st.metric("ì„¹ì…˜3 ê¸¸ì´", f"{len(sec3):,}")
        st.download_button("TXT (ì„¹ì…˜3)", data=to_txt_bytes(sec3), file_name=f"{os.path.splitext(up.name)[0]}__section3.txt", use_container_width=True, disabled=(not sec3))

    # ìš”ì•½í–‰
    summary_rows.append({
        "file": up.name,
        "detected_sections": len(sections),
        "has_section3": bool(sec3),
        "len_fulltext": len(full_text),
        "len_sec3": len(sec3),
    })

# ì „ì²´ ìš”ì•½
st.markdown("---")
st.subheader("ğŸ“Š íŒŒì¼ë³„ ìš”ì•½")
sumdf = pd.DataFrame(summary_rows)
st.dataframe(sumdf, use_container_width=True, hide_index=True)
